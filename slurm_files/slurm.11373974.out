{'GPU': None, 'model_name': 'swin_base', 'init': 'imagenet', 'pretrained_weights': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth', 'from_checkpoint': False, 'dataset_list': ['MIMIC', 'CheXpert', 'ChestXray14', 'RSNAPneumonia', 'VinDrCXR', 'Shenzhen'], 'normalization': 'imagenet', 'img_size': 224, 'img_depth': 3, 'batch_size': 200, 'epochs': 200, 'exp_name': '', 'ema_mode': 'epoch', 'momentum_teacher': 0.9, 'pretrain_epochs': 200, 'test_epoch': 10, 'val_loss_metric': 'average', 'projector_features': 1376, 'use_mlp': False, 'opt': 'sgd', 'opt_eps': 1e-08, 'opt_betas': None, 'clip_grad': None, 'momentum': 0.9, 'weight_decay': 0.0, 'sched': 'cosine', 'lr': 0.3, 'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, 'warmup_lr': 1e-06, 'min_lr': 1e-05, 'decay_epochs': 30, 'warmup_epochs': 20, 'cooldown_epochs': 10, 'decay_rate': 0.5, 'patience_epochs': 10, 'resume': False, 'workers': 8, 'print_freq': 50, 'test_augment': True, 'anno_percent': 100, 'device': 'cuda', 'activate': 'Sigmoid', 'uncertain_label': 'LSR-Ones', 'unknown_label': 0}
num_classes_list: [14, 14, 14, 3, 6, 1]
Loaded with msg: _IncompatibleKeys(missing_keys=['projector.weight', 'projector.bias', 'omni_heads.0.weight', 'omni_heads.0.bias', 'omni_heads.1.weight', 'omni_heads.1.bias', 'omni_heads.2.weight', 'omni_heads.2.bias', 'omni_heads.3.weight', 'omni_heads.3.bias', 'omni_heads.4.weight', 'omni_heads.4.bias', 'omni_heads.5.weight', 'omni_heads.5.bias'], unexpected_keys=[])
Loaded with msg: _IncompatibleKeys(missing_keys=['projector.weight', 'projector.bias', 'omni_heads.0.weight', 'omni_heads.0.bias', 'omni_heads.1.weight', 'omni_heads.1.bias', 'omni_heads.2.weight', 'omni_heads.2.bias', 'omni_heads.3.weight', 'omni_heads.3.bias', 'omni_heads.4.weight', 'omni_heads.4.bias', 'omni_heads.5.weight', 'omni_heads.5.bias'], unexpected_keys=[])
ArkSwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): Sequential(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
  (projector): Linear(in_features=1024, out_features=1376, bias=True)
  (omni_heads): ModuleList(
    (0): Linear(in_features=1376, out_features=14, bias=True)
    (1): Linear(in_features=1376, out_features=14, bias=True)
    (2): Linear(in_features=1376, out_features=14, bias=True)
    (3): Linear(in_features=1376, out_features=3, bias=True)
    (4): Linear(in_features=1376, out_features=6, bias=True)
    (5): Linear(in_features=1376, out_features=1, bias=True)
  )
)
Student and Teacher are built: they are both swin_base network.
0.0
Epoch: [0][   0/1845]	Time 72.659 (72.659)	Loss_MIMIC cls 6.9365e-01 (6.9365e-01)	Loss_MIMIC mse 2.0544e-01 (2.0544e-01)
Epoch: [0][  50/1845]	Time  2.012 ( 5.627)	Loss_MIMIC cls 6.9364e-01 (6.9337e-01)	Loss_MIMIC mse 2.0697e-01 (2.0527e-01)
Epoch: [0][ 100/1845]	Time  2.013 ( 5.184)	Loss_MIMIC cls 6.9316e-01 (6.9289e-01)	Loss_MIMIC mse 2.0452e-01 (2.0474e-01)
Epoch: [0][ 150/1845]	Time  2.013 ( 5.043)	Loss_MIMIC cls 6.9271e-01 (6.9265e-01)	Loss_MIMIC mse 2.1204e-01 (2.0493e-01)
Epoch: [0][ 200/1845]	Time 18.682 ( 5.055)	Loss_MIMIC cls 6.9033e-01 (6.9232e-01)	Loss_MIMIC mse 2.0516e-01 (2.0484e-01)
Epoch: [0][ 250/1845]	Time 16.041 ( 5.038)	Loss_MIMIC cls 6.8946e-01 (6.9191e-01)	Loss_MIMIC mse 2.0371e-01 (2.0488e-01)
Epoch: [0][ 300/1845]	Time  2.019 ( 4.993)	Loss_MIMIC cls 6.8870e-01 (6.9158e-01)	Loss_MIMIC mse 2.0831e-01 (2.0502e-01)
Epoch: [0][ 350/1845]	Time  2.012 ( 4.959)	Loss_MIMIC cls 6.9054e-01 (6.9119e-01)	Loss_MIMIC mse 2.0926e-01 (2.0498e-01)
Epoch: [0][ 400/1845]	Time  2.012 ( 4.934)	Loss_MIMIC cls 6.8755e-01 (6.9079e-01)	Loss_MIMIC mse 2.0043e-01 (2.0499e-01)
Epoch: [0][ 450/1845]	Time 24.881 ( 4.977)	Loss_MIMIC cls 6.8530e-01 (6.9037e-01)	Loss_MIMIC mse 2.0932e-01 (2.0503e-01)
Epoch: [0][ 500/1845]	Time  2.014 ( 4.963)	Loss_MIMIC cls 6.8683e-01 (6.8995e-01)	Loss_MIMIC mse 2.0832e-01 (2.0504e-01)
Epoch: [0][ 550/1845]	Time  2.012 ( 4.959)	Loss_MIMIC cls 6.8656e-01 (6.8954e-01)	Loss_MIMIC mse 2.0032e-01 (2.0500e-01)
Epoch: [0][ 600/1845]	Time  2.016 ( 4.952)	Loss_MIMIC cls 6.8527e-01 (6.8910e-01)	Loss_MIMIC mse 2.0302e-01 (2.0505e-01)
Epoch: [0][ 650/1845]	Time 26.248 ( 4.978)	Loss_MIMIC cls 6.8309e-01 (6.8868e-01)	Loss_MIMIC mse 2.0809e-01 (2.0507e-01)
Epoch: [0][ 700/1845]	Time  2.012 ( 4.961)	Loss_MIMIC cls 6.8281e-01 (6.8828e-01)	Loss_MIMIC mse 2.0524e-01 (2.0509e-01)
Epoch: [0][ 750/1845]	Time  2.012 ( 4.953)	Loss_MIMIC cls 6.8016e-01 (6.8790e-01)	Loss_MIMIC mse 2.0642e-01 (2.0511e-01)
Epoch: [0][ 800/1845]	Time  2.013 ( 4.947)	Loss_MIMIC cls 6.8392e-01 (6.8751e-01)	Loss_MIMIC mse 2.0658e-01 (2.0503e-01)
Epoch: [0][ 850/1845]	Time 25.800 ( 4.969)	Loss_MIMIC cls 6.7964e-01 (6.8712e-01)	Loss_MIMIC mse 2.0262e-01 (2.0500e-01)
Epoch: [0][ 900/1845]	Time  2.013 ( 4.965)	Loss_MIMIC cls 6.8285e-01 (6.8674e-01)	Loss_MIMIC mse 2.0753e-01 (2.0503e-01)
Epoch: [0][ 950/1845]	Time  2.017 ( 4.960)	Loss_MIMIC cls 6.7843e-01 (6.8634e-01)	Loss_MIMIC mse 2.0026e-01 (2.0501e-01)
Epoch: [0][1000/1845]	Time  2.014 ( 4.957)	Loss_MIMIC cls 6.7560e-01 (6.8597e-01)	Loss_MIMIC mse 2.0634e-01 (2.0503e-01)
Epoch: [0][1050/1845]	Time 28.082 ( 4.975)	Loss_MIMIC cls 6.7858e-01 (6.8560e-01)	Loss_MIMIC mse 2.0747e-01 (2.0506e-01)
Epoch: [0][1100/1845]	Time  2.013 ( 4.973)	Loss_MIMIC cls 6.7876e-01 (6.8519e-01)	Loss_MIMIC mse 2.0602e-01 (2.0507e-01)
Epoch: [0][1150/1845]	Time  2.016 ( 4.964)	Loss_MIMIC cls 6.7650e-01 (6.8481e-01)	Loss_MIMIC mse 2.0637e-01 (2.0511e-01)
Epoch: [0][1200/1845]	Time  2.014 ( 4.962)	Loss_MIMIC cls 6.7572e-01 (6.8442e-01)	Loss_MIMIC mse 2.1005e-01 (2.0512e-01)
Epoch: [0][1250/1845]	Time 24.342 ( 4.976)	Loss_MIMIC cls 6.7606e-01 (6.8405e-01)	Loss_MIMIC mse 2.1065e-01 (2.0515e-01)
Epoch: [0][1300/1845]	Time  2.014 ( 4.970)	Loss_MIMIC cls 6.7399e-01 (6.8366e-01)	Loss_MIMIC mse 2.0694e-01 (2.0517e-01)
Epoch: [0][1350/1845]	Time  2.012 ( 4.964)	Loss_MIMIC cls 6.7009e-01 (6.8327e-01)	Loss_MIMIC mse 2.0476e-01 (2.0516e-01)
Epoch: [0][1400/1845]	Time  2.014 ( 4.962)	Loss_MIMIC cls 6.7237e-01 (6.8287e-01)	Loss_MIMIC mse 2.0649e-01 (2.0515e-01)
Epoch: [0][1450/1845]	Time 24.910 ( 4.975)	Loss_MIMIC cls 6.7092e-01 (6.8250e-01)	Loss_MIMIC mse 2.0226e-01 (2.0518e-01)
Epoch: [0][1500/1845]	Time  2.012 ( 4.971)	Loss_MIMIC cls 6.6962e-01 (6.8212e-01)	Loss_MIMIC mse 2.0267e-01 (2.0520e-01)
Epoch: [0][1550/1845]	Time  2.014 ( 4.967)	Loss_MIMIC cls 6.6783e-01 (6.8173e-01)	Loss_MIMIC mse 2.0311e-01 (2.0522e-01)
Epoch: [0][1600/1845]	Time  2.012 ( 4.961)	Loss_MIMIC cls 6.6922e-01 (6.8136e-01)	Loss_MIMIC mse 2.0572e-01 (2.0520e-01)
Epoch: [0][1650/1845]	Time 24.687 ( 4.970)	Loss_MIMIC cls 6.7036e-01 (6.8098e-01)	Loss_MIMIC mse 2.0328e-01 (2.0520e-01)
Epoch: [0][1700/1845]	Time  2.014 ( 4.964)	Loss_MIMIC cls 6.6776e-01 (6.8059e-01)	Loss_MIMIC mse 2.0533e-01 (2.0522e-01)
Epoch: [0][1750/1845]	Time  2.014 ( 4.962)	Loss_MIMIC cls 6.6856e-01 (6.8021e-01)	Loss_MIMIC mse 2.0868e-01 (2.0524e-01)
Epoch: [0][1800/1845]	Time  2.014 ( 4.960)	Loss_MIMIC cls 6.6634e-01 (6.7983e-01)	Loss_MIMIC mse 2.0503e-01 (2.0524e-01)
8.567360038069793e-07
Epoch: [0][   0/1118]	Time 51.472 (51.472)	Loss_CheXpert cls 7.2414e-01 (7.2414e-01)	Loss_CheXpert mse 1.7468e-01 (1.7468e-01)
Epoch: [0][  50/1118]	Time  2.012 ( 6.324)	Loss_CheXpert cls 7.2282e-01 (7.2341e-01)	Loss_CheXpert mse 1.7207e-01 (1.7621e-01)
Epoch: [0][ 100/1118]	Time  2.014 ( 5.819)	Loss_CheXpert cls 7.2133e-01 (7.2282e-01)	Loss_CheXpert mse 1.7362e-01 (1.7562e-01)
Epoch: [0][ 150/1118]	Time  2.013 ( 5.654)	Loss_CheXpert cls 7.2389e-01 (7.2240e-01)	Loss_CheXpert mse 1.7502e-01 (1.7521e-01)
Epoch: [0][ 200/1118]	Time  8.100 ( 5.621)	Loss_CheXpert cls 7.2078e-01 (7.2208e-01)	Loss_CheXpert mse 1.7491e-01 (1.7519e-01)
Epoch: [0][ 250/1118]	Time  2.012 ( 5.558)	Loss_CheXpert cls 7.1840e-01 (7.2161e-01)	Loss_CheXpert mse 1.7480e-01 (1.7514e-01)
Epoch: [0][ 300/1118]	Time  2.015 ( 5.601)	Loss_CheXpert cls 7.1957e-01 (7.2124e-01)	Loss_CheXpert mse 1.7531e-01 (1.7519e-01)
Epoch: [0][ 350/1118]	Time  2.016 ( 5.583)	Loss_CheXpert cls 7.1725e-01 (7.2085e-01)	Loss_CheXpert mse 1.7423e-01 (1.7516e-01)
Epoch: [0][ 400/1118]	Time  2.012 ( 5.544)	Loss_CheXpert cls 7.1925e-01 (7.2045e-01)	Loss_CheXpert mse 1.7556e-01 (1.7515e-01)
Epoch: [0][ 450/1118]	Time  2.012 ( 5.507)	Loss_CheXpert cls 7.1592e-01 (7.2006e-01)	Loss_CheXpert mse 1.6830e-01 (1.7507e-01)
Epoch: [0][ 500/1118]	Time  2.013 ( 5.537)	Loss_CheXpert cls 7.1528e-01 (7.1964e-01)	Loss_CheXpert mse 1.7410e-01 (1.7500e-01)
Epoch: [0][ 550/1118]	Time  2.013 ( 5.519)	Loss_CheXpert cls 7.1664e-01 (7.1924e-01)	Loss_CheXpert mse 1.7528e-01 (1.7485e-01)
Epoch: [0][ 600/1118]	Time  2.013 ( 5.497)	Loss_CheXpert cls 7.1626e-01 (7.1884e-01)	Loss_CheXpert mse 1.7272e-01 (1.7478e-01)
Epoch: [0][ 650/1118]	Time  2.011 ( 5.486)	Loss_CheXpert cls 7.1594e-01 (7.1844e-01)	Loss_CheXpert mse 1.7033e-01 (1.7469e-01)
Epoch: [0][ 700/1118]	Time  2.015 ( 5.502)	Loss_CheXpert cls 7.1181e-01 (7.1804e-01)	Loss_CheXpert mse 1.6914e-01 (1.7466e-01)
Epoch: [0][ 750/1118]	Time  2.015 ( 5.480)	Loss_CheXpert cls 7.1102e-01 (7.1763e-01)	Loss_CheXpert mse 1.7244e-01 (1.7460e-01)
Epoch: [0][ 800/1118]	Time  2.016 ( 5.465)	Loss_CheXpert cls 7.1188e-01 (7.1724e-01)	Loss_CheXpert mse 1.7466e-01 (1.7455e-01)
Epoch: [0][ 850/1118]	Time  2.015 ( 5.449)	Loss_CheXpert cls 7.1002e-01 (7.1687e-01)	Loss_CheXpert mse 1.7059e-01 (1.7446e-01)
Epoch: [0][ 900/1118]	Time  2.012 ( 5.465)	Loss_CheXpert cls 7.0911e-01 (7.1650e-01)	Loss_CheXpert mse 1.7521e-01 (1.7441e-01)
Epoch: [0][ 950/1118]	Time  2.013 ( 5.448)	Loss_CheXpert cls 7.0884e-01 (7.1610e-01)	Loss_CheXpert mse 1.8110e-01 (1.7437e-01)
Epoch: [0][1000/1118]	Time  2.013 ( 5.432)	Loss_CheXpert cls 7.0855e-01 (7.1570e-01)	Loss_CheXpert mse 1.7600e-01 (1.7432e-01)
Epoch: [0][1050/1118]	Time  2.013 ( 5.419)	Loss_CheXpert cls 7.0923e-01 (7.1531e-01)	Loss_CheXpert mse 1.6907e-01 (1.7425e-01)
Epoch: [0][1100/1118]	Time  2.014 ( 5.435)	Loss_CheXpert cls 7.0737e-01 (7.1492e-01)	Loss_CheXpert mse 1.7125e-01 (1.7420e-01)
3.4269381433138513e-06
Epoch: [0][  0/377]	Time 15.609 (15.609)	Loss_ChestXray14 cls 7.1226e-01 (7.1226e-01)	Loss_ChestXray14 mse 1.2199e-01 (1.2199e-01)
Epoch: [0][ 50/377]	Time  2.013 ( 2.280)	Loss_ChestXray14 cls 7.1133e-01 (7.1132e-01)	Loss_ChestXray14 mse 1.1763e-01 (1.1963e-01)
Epoch: [0][100/377]	Time  2.011 ( 2.147)	Loss_ChestXray14 cls 7.1018e-01 (7.1058e-01)	Loss_ChestXray14 mse 1.1956e-01 (1.1981e-01)
Epoch: [0][150/377]	Time  2.012 ( 2.103)	Loss_ChestXray14 cls 7.0959e-01 (7.0984e-01)	Loss_ChestXray14 mse 1.1962e-01 (1.1978e-01)
Epoch: [0][200/377]	Time  2.011 ( 2.080)	Loss_ChestXray14 cls 7.0536e-01 (7.0911e-01)	Loss_ChestXray14 mse 1.2035e-01 (1.1975e-01)
Epoch: [0][250/377]	Time  2.010 ( 2.066)	Loss_ChestXray14 cls 7.0553e-01 (7.0839e-01)	Loss_ChestXray14 mse 1.2208e-01 (1.1970e-01)
Epoch: [0][300/377]	Time  2.010 ( 2.057)	Loss_ChestXray14 cls 7.0367e-01 (7.0769e-01)	Loss_ChestXray14 mse 1.2042e-01 (1.1972e-01)
Epoch: [0][350/377]	Time  2.010 ( 2.051)	Loss_ChestXray14 cls 7.0158e-01 (7.0693e-01)	Loss_ChestXray14 mse 1.1976e-01 (1.1971e-01)
7.710588802556373e-06
Epoch: [0][  0/107]	Time 12.522 (12.522)	Loss_RSNAPneumonia cls 6.9270e-01 (6.9270e-01)	Loss_RSNAPneumonia mse 1.0177e-01 (1.0177e-01)
Epoch: [0][ 50/107]	Time  2.011 ( 2.218)	Loss_RSNAPneumonia cls 6.9372e-01 (6.9310e-01)	Loss_RSNAPneumonia mse 1.0044e-01 (1.0098e-01)
Epoch: [0][100/107]	Time  2.013 ( 2.115)	Loss_RSNAPneumonia cls 6.9232e-01 (6.9277e-01)	Loss_RSNAPneumonia mse 1.0131e-01 (1.0135e-01)
1.3707658621964214e-05
Epoch: [0][ 0/75]	Time 30.957 (30.957)	Loss_VinDrCXR cls 6.8173e-01 (6.8173e-01)	Loss_VinDrCXR mse 8.8494e-02 (8.8494e-02)
Epoch: [0][50/75]	Time  2.011 ( 4.345)	Loss_VinDrCXR cls 6.8302e-01 (6.8309e-01)	Loss_VinDrCXR mse 9.0986e-02 (8.9166e-02)
2.1418106498249934e-05
Epoch: [0][0/3]	Time 44.683 (44.683)	Loss_Shenzhen cls 7.0349e-01 (7.0349e-01)	Loss_Shenzhen mse 6.7279e-02 (6.7279e-02)
Val_MIMIC: [ 0/15]	Time 49.493 (49.493)	Loss 6.6859e-01 (6.6859e-01)
Val_CheXpert: [0/2]	Time 45.914 (45.914)	Loss 7.0309e-01 (7.0309e-01)
Val_ChestXray14: [ 0/57]	Time 10.887 (10.887)	Loss 7.0512e-01 (7.0512e-01)
Val_ChestXray14: [50/57]	Time  0.496 ( 1.425)	Loss 7.0679e-01 (7.0618e-01)
Val_RSNAPneumonia: [ 0/14]	Time 12.224 (12.224)	Loss 6.9157e-01 (6.9157e-01)
Val_VinDrCXR: [ 0/15]	Time 27.572 (27.572)	Loss 6.6883e-01 (6.6883e-01)
Val_Shenzhen: [0/1]	Time 17.675 (17.675)	Loss 6.9543e-01 (6.9543e-01)
Epoch 0000: avg_val_loss 0.68803, saving model to ./Models/swin_base_imagenet/Ark_MIMIC_CheXpert_ChestXray14_RSNAPneumonia_VinDrCXR_Shenzhen/Ark_MIMIC_CheXpert_ChestXray14_RSNAPneumonia_VinDrCXR_Shenzhen
>>MIMIC Disease = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']
>>MIMIC:Student AUC = [0.4873	0.4549	0.5234	0.5745	0.5278	0.4155	0.5033	0.4989	0.4618	0.506
 0.4968	0.4889	0.5449	0.4349], 
Teacher AUC = [0.4741	0.4967	0.4686	0.5756	0.5423	0.404 	0.5117	0.5139	0.4143	0.5239
 0.5364	0.5129	0.5483	0.5236]

>>MIMIC: Student mAUC = 0.4942, Teacher mAUC = 0.5033
>>CheXpert Disease = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']
>>CheXpert:Student AUC = [0.4073	0.5192	0.577 	0.525 	0.717 ], 
Teacher AUC = [0.4073	0.5099	0.3713	0.4945	0.5432]

>>CheXpert: Student mAUC = 0.5491, Teacher mAUC = 0.4653
>>ChestXray14 Disease = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']
