{'GPU': None, 'model_name': 'swinv2_large', 'init': 'imagenet', 'pretrained_weights': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth', 'from_checkpoint': False, 'dataset_list': ['MIMIC', 'CheXpert', 'ChestXray14', 'RSNAPneumonia', 'VinDrCXR', 'Shenzhen'], 'normalization': 'imagenet', 'img_size': 256, 'img_depth': 3, 'batch_size': 200, 'epochs': 200, 'exp_name': '', 'ema_mode': 'epoch', 'momentum_teacher': 0.9, 'pretrain_epochs': 200, 'test_epoch': 10, 'val_loss_metric': 'average', 'projector_features': 1376, 'use_mlp': False, 'opt': 'sgd', 'opt_eps': 1e-08, 'opt_betas': None, 'clip_grad': None, 'momentum': 0.9, 'weight_decay': 0.0, 'sched': 'cosine', 'lr': 0.3, 'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, 'warmup_lr': 1e-06, 'min_lr': 1e-05, 'decay_epochs': 30, 'warmup_epochs': 20, 'cooldown_epochs': 10, 'decay_rate': 0.5, 'patience_epochs': 10, 'resume': False, 'workers': 16, 'print_freq': 50, 'test_augment': True, 'anno_percent': 100, 'device': 'cuda', 'activate': 'Sigmoid', 'uncertain_label': 'LSR-Ones', 'unknown_label': 0}
cuda
num_classes_list: [14, 14, 14, 3, 6, 1]
Custom Test Model:
SwinTransformerV2(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (layers): Sequential(
    (0): SwinTransformerV2Stage(
      (downsample): Identity()
      (blocks): ModuleList(
        (0): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=6, bias=False)
            )
            (qkv): Linear(in_features=192, out_features=576, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (drop_path1): Identity()
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (drop_path2): Identity()
        )
        (1): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=6, bias=False)
            )
            (qkv): Linear(in_features=192, out_features=576, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.004)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.004)
        )
      )
    )
    (1): SwinTransformerV2Stage(
      (downsample): PatchMerging(
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
      (blocks): ModuleList(
        (0): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=12, bias=False)
            )
            (qkv): Linear(in_features=384, out_features=1152, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.009)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.009)
        )
        (1): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=12, bias=False)
            )
            (qkv): Linear(in_features=384, out_features=1152, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.013)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.013)
        )
      )
    )
    (2): SwinTransformerV2Stage(
      (downsample): PatchMerging(
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (blocks): ModuleList(
        (0): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.017)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.017)
        )
        (1): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.022)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.022)
        )
        (2): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.026)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.026)
        )
        (3): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.030)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.030)
        )
        (4): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.035)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.035)
        )
        (5): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.039)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.039)
        )
        (6): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.043)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.043)
        )
        (7): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.048)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.048)
        )
        (8): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.052)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.052)
        )
        (9): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.057)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.057)
        )
        (10): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.061)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.061)
        )
        (11): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.065)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.065)
        )
        (12): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.070)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.070)
        )
        (13): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.074)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.074)
        )
        (14): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.078)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.078)
        )
        (15): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.083)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.083)
        )
        (16): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.087)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.087)
        )
        (17): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=24, bias=False)
            )
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.091)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.091)
        )
      )
    )
    (3): SwinTransformerV2Stage(
      (downsample): PatchMerging(
        (reduction): Linear(in_features=3072, out_features=1536, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
      (blocks): ModuleList(
        (0): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=48, bias=False)
            )
            (qkv): Linear(in_features=1536, out_features=4608, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.096)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.096)
        )
        (1): SwinTransformerV2Block(
          (attn): WindowAttention(
            (cpb_mlp): Sequential(
              (0): Linear(in_features=2, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=48, bias=False)
            )
            (qkv): Linear(in_features=1536, out_features=4608, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (drop_path1): DropPath(drop_prob=0.100)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (drop_path2): DropPath(drop_prob=0.100)
        )
      )
    )
  )
  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (head): ClassifierHead(
    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
    (drop): Dropout(p=0.0, inplace=False)
    (fc): Identity()
    (flatten): Identity()
  )
)
Projector: Linear(in_features=1536, out_features=1376, bias=True)
Omni Heads: ModuleList(
  (0-2): 3 x Linear(in_features=1376, out_features=14, bias=True)
  (3): Linear(in_features=1376, out_features=3, bias=True)
  (4): Linear(in_features=1376, out_features=6, bias=True)
  (5): Linear(in_features=1376, out_features=1, bias=True)
)
Student and Teacher are built: they are both swinv2_large network.
0.0
Epoch: [0][   0/1845]	Time 61.114 (61.114)	Loss_MIMIC cls 7.0410e-01 (7.0410e-01)	Loss_MIMIC mse 4.0259e-01 (4.0259e-01)
Epoch: [0][  50/1845]	Time  2.555 ( 3.829)	Loss_MIMIC cls 7.0225e-01 (7.0487e-01)	Loss_MIMIC mse 3.9636e-01 (3.9876e-01)
Epoch: [0][ 100/1845]	Time  2.614 ( 3.364)	Loss_MIMIC cls 7.0093e-01 (7.0344e-01)	Loss_MIMIC mse 3.9481e-01 (3.9807e-01)
Epoch: [0][ 150/1845]	Time  2.637 ( 3.188)	Loss_MIMIC cls 6.9986e-01 (7.0199e-01)	Loss_MIMIC mse 3.9139e-01 (3.9733e-01)
Epoch: [0][ 200/1845]	Time  2.557 ( 3.104)	Loss_MIMIC cls 6.9644e-01 (7.0075e-01)	Loss_MIMIC mse 3.9353e-01 (3.9648e-01)
Epoch: [0][ 250/1845]	Time  2.588 ( 3.067)	Loss_MIMIC cls 6.9524e-01 (6.9945e-01)	Loss_MIMIC mse 3.8937e-01 (3.9579e-01)
Epoch: [0][ 300/1845]	Time  2.589 ( 3.055)	Loss_MIMIC cls 6.9233e-01 (6.9826e-01)	Loss_MIMIC mse 3.8794e-01 (3.9492e-01)
Epoch: [0][ 350/1845]	Time  2.578 ( 3.031)	Loss_MIMIC cls 6.8964e-01 (6.9701e-01)	Loss_MIMIC mse 4.0141e-01 (3.9470e-01)
Epoch: [0][ 400/1845]	Time  2.563 ( 3.002)	Loss_MIMIC cls 6.8656e-01 (6.9580e-01)	Loss_MIMIC mse 3.9051e-01 (3.9416e-01)
Epoch: [0][ 450/1845]	Time  2.647 ( 2.987)	Loss_MIMIC cls 6.8410e-01 (6.9468e-01)	Loss_MIMIC mse 3.9406e-01 (3.9390e-01)
Epoch: [0][ 500/1845]	Time  2.565 ( 2.967)	Loss_MIMIC cls 6.8321e-01 (6.9352e-01)	Loss_MIMIC mse 3.8444e-01 (3.9355e-01)
Epoch: [0][ 550/1845]	Time  2.587 ( 2.960)	Loss_MIMIC cls 6.8042e-01 (6.9238e-01)	Loss_MIMIC mse 3.9658e-01 (3.9340e-01)
Epoch: [0][ 600/1845]	Time  2.565 ( 2.950)	Loss_MIMIC cls 6.7991e-01 (6.9126e-01)	Loss_MIMIC mse 3.8816e-01 (3.9340e-01)
Epoch: [0][ 650/1845]	Time  2.696 ( 2.936)	Loss_MIMIC cls 6.7524e-01 (6.9015e-01)	Loss_MIMIC mse 3.9243e-01 (3.9314e-01)
Epoch: [0][ 700/1845]	Time  2.658 ( 2.928)	Loss_MIMIC cls 6.7685e-01 (6.8907e-01)	Loss_MIMIC mse 3.8685e-01 (3.9305e-01)
Epoch: [0][ 750/1845]	Time  2.620 ( 2.915)	Loss_MIMIC cls 6.7000e-01 (6.8798e-01)	Loss_MIMIC mse 3.8590e-01 (3.9298e-01)
Epoch: [0][ 800/1845]	Time  2.642 ( 2.904)	Loss_MIMIC cls 6.7152e-01 (6.8691e-01)	Loss_MIMIC mse 4.0170e-01 (3.9294e-01)
Epoch: [0][ 850/1845]	Time  2.638 ( 2.891)	Loss_MIMIC cls 6.6590e-01 (6.8580e-01)	Loss_MIMIC mse 3.9948e-01 (3.9308e-01)
Epoch: [0][ 900/1845]	Time  2.608 ( 2.883)	Loss_MIMIC cls 6.6523e-01 (6.8472e-01)	Loss_MIMIC mse 3.8865e-01 (3.9300e-01)
Epoch: [0][ 950/1845]	Time  2.926 ( 2.879)	Loss_MIMIC cls 6.6550e-01 (6.8362e-01)	Loss_MIMIC mse 3.8804e-01 (3.9297e-01)
Epoch: [0][1000/1845]	Time  2.671 ( 2.872)	Loss_MIMIC cls 6.6392e-01 (6.8254e-01)	Loss_MIMIC mse 3.9541e-01 (3.9311e-01)
Epoch: [0][1050/1845]	Time  2.540 ( 2.867)	Loss_MIMIC cls 6.5669e-01 (6.8146e-01)	Loss_MIMIC mse 4.1168e-01 (3.9341e-01)
Epoch: [0][1100/1845]	Time  2.595 ( 2.870)	Loss_MIMIC cls 6.5692e-01 (6.8039e-01)	Loss_MIMIC mse 3.9945e-01 (3.9359e-01)
Epoch: [0][1150/1845]	Time  2.595 ( 2.867)	Loss_MIMIC cls 6.5664e-01 (6.7931e-01)	Loss_MIMIC mse 3.8119e-01 (3.9378e-01)
Epoch: [0][1200/1845]	Time  2.606 ( 2.865)	Loss_MIMIC cls 6.5246e-01 (6.7825e-01)	Loss_MIMIC mse 3.9677e-01 (3.9404e-01)
Epoch: [0][1250/1845]	Time  2.534 ( 2.863)	Loss_MIMIC cls 6.5072e-01 (6.7720e-01)	Loss_MIMIC mse 3.9088e-01 (3.9424e-01)
Epoch: [0][1300/1845]	Time  2.602 ( 2.859)	Loss_MIMIC cls 6.4493e-01 (6.7616e-01)	Loss_MIMIC mse 4.2189e-01 (3.9446e-01)
Epoch: [0][1350/1845]	Time  2.563 ( 2.856)	Loss_MIMIC cls 6.4677e-01 (6.7510e-01)	Loss_MIMIC mse 4.0915e-01 (3.9473e-01)
Epoch: [0][1400/1845]	Time  3.168 ( 2.854)	Loss_MIMIC cls 6.4418e-01 (6.7405e-01)	Loss_MIMIC mse 3.8697e-01 (3.9499e-01)
Epoch: [0][1450/1845]	Time  2.667 ( 2.852)	Loss_MIMIC cls 6.3973e-01 (6.7301e-01)	Loss_MIMIC mse 4.3593e-01 (3.9529e-01)
Epoch: [0][1500/1845]	Time  2.565 ( 2.852)	Loss_MIMIC cls 6.4442e-01 (6.7196e-01)	Loss_MIMIC mse 3.9855e-01 (3.9566e-01)
Epoch: [0][1550/1845]	Time  2.867 ( 2.849)	Loss_MIMIC cls 6.4152e-01 (6.7092e-01)	Loss_MIMIC mse 4.1311e-01 (3.9606e-01)
Epoch: [0][1600/1845]	Time  2.669 ( 2.846)	Loss_MIMIC cls 6.3300e-01 (6.6986e-01)	Loss_MIMIC mse 4.0623e-01 (3.9649e-01)
Epoch: [0][1650/1845]	Time  2.596 ( 2.840)	Loss_MIMIC cls 6.3357e-01 (6.6878e-01)	Loss_MIMIC mse 3.9543e-01 (3.9690e-01)
Epoch: [0][1700/1845]	Time  2.771 ( 2.835)	Loss_MIMIC cls 6.3402e-01 (6.6772e-01)	Loss_MIMIC mse 4.0987e-01 (3.9735e-01)
Epoch: [0][1750/1845]	Time  2.572 ( 2.837)	Loss_MIMIC cls 6.2776e-01 (6.6665e-01)	Loss_MIMIC mse 4.0190e-01 (3.9784e-01)
Epoch: [0][1800/1845]	Time  2.555 ( 2.835)	Loss_MIMIC cls 6.2775e-01 (6.6558e-01)	Loss_MIMIC mse 4.2103e-01 (3.9837e-01)
8.567360038069793e-07
Epoch: [0][   0/1118]	Time 56.671 (56.671)	Loss_CheXpert cls 7.1123e-01 (7.1123e-01)	Loss_CheXpert mse 3.6299e-01 (3.6299e-01)
Epoch: [0][  50/1118]	Time  2.613 ( 4.432)	Loss_CheXpert cls 7.0827e-01 (7.0860e-01)	Loss_CheXpert mse 3.7188e-01 (3.6228e-01)
Epoch: [0][ 100/1118]	Time  2.767 ( 3.920)	Loss_CheXpert cls 7.0432e-01 (7.0683e-01)	Loss_CheXpert mse 3.6195e-01 (3.6122e-01)
Epoch: [0][ 150/1118]	Time  2.802 ( 3.727)	Loss_CheXpert cls 7.0383e-01 (7.0526e-01)	Loss_CheXpert mse 3.6739e-01 (3.5951e-01)
Epoch: [0][ 200/1118]	Time  2.585 ( 3.635)	Loss_CheXpert cls 6.9694e-01 (7.0378e-01)	Loss_CheXpert mse 3.4223e-01 (3.5789e-01)
Epoch: [0][ 250/1118]	Time  2.662 ( 3.585)	Loss_CheXpert cls 6.9622e-01 (7.0243e-01)	Loss_CheXpert mse 3.4891e-01 (3.5664e-01)
Epoch: [0][ 300/1118]	Time  2.795 ( 3.548)	Loss_CheXpert cls 6.9166e-01 (7.0112e-01)	Loss_CheXpert mse 3.4570e-01 (3.5552e-01)
Epoch: [0][ 350/1118]	Time  2.684 ( 3.508)	Loss_CheXpert cls 6.9421e-01 (6.9990e-01)	Loss_CheXpert mse 3.4829e-01 (3.5432e-01)
Epoch: [0][ 400/1118]	Time  6.424 ( 3.484)	Loss_CheXpert cls 6.8946e-01 (6.9872e-01)	Loss_CheXpert mse 3.5515e-01 (3.5338e-01)
Epoch: [0][ 450/1118]	Time  2.746 ( 3.461)	Loss_CheXpert cls 6.9003e-01 (6.9752e-01)	Loss_CheXpert mse 3.4801e-01 (3.5247e-01)
Epoch: [0][ 500/1118]	Time  2.761 ( 3.430)	Loss_CheXpert cls 6.8527e-01 (6.9632e-01)	Loss_CheXpert mse 3.4439e-01 (3.5156e-01)
Epoch: [0][ 550/1118]	Time  2.651 ( 3.409)	Loss_CheXpert cls 6.8375e-01 (6.9517e-01)	Loss_CheXpert mse 3.4208e-01 (3.5087e-01)
Epoch: [0][ 600/1118]	Time  2.664 ( 3.386)	Loss_CheXpert cls 6.7986e-01 (6.9402e-01)	Loss_CheXpert mse 3.4542e-01 (3.5031e-01)
Epoch: [0][ 650/1118]	Time  2.580 ( 3.362)	Loss_CheXpert cls 6.7851e-01 (6.9289e-01)	Loss_CheXpert mse 3.3942e-01 (3.4975e-01)
Epoch: [0][ 700/1118]	Time  2.687 ( 3.341)	Loss_CheXpert cls 6.7474e-01 (6.9178e-01)	Loss_CheXpert mse 3.3903e-01 (3.4917e-01)
Epoch: [0][ 750/1118]	Time  2.550 ( 3.306)	Loss_CheXpert cls 6.7495e-01 (6.9070e-01)	Loss_CheXpert mse 3.3029e-01 (3.4869e-01)
Epoch: [0][ 800/1118]	Time  2.745 ( 3.292)	Loss_CheXpert cls 6.7289e-01 (6.8960e-01)	Loss_CheXpert mse 3.5820e-01 (3.4831e-01)
Epoch: [0][ 850/1118]	Time  2.695 ( 3.280)	Loss_CheXpert cls 6.7045e-01 (6.8856e-01)	Loss_CheXpert mse 3.4954e-01 (3.4794e-01)
Epoch: [0][ 900/1118]	Time  2.623 ( 3.270)	Loss_CheXpert cls 6.6693e-01 (6.8751e-01)	Loss_CheXpert mse 3.3369e-01 (3.4757e-01)
Epoch: [0][ 950/1118]	Time  5.196 ( 3.264)	Loss_CheXpert cls 6.6968e-01 (6.8646e-01)	Loss_CheXpert mse 3.3041e-01 (3.4727e-01)
Epoch: [0][1000/1118]	Time  2.623 ( 3.253)	Loss_CheXpert cls 6.6322e-01 (6.8544e-01)	Loss_CheXpert mse 3.3443e-01 (3.4700e-01)
Epoch: [0][1050/1118]	Time  2.788 ( 3.247)	Loss_CheXpert cls 6.6113e-01 (6.8441e-01)	Loss_CheXpert mse 3.3274e-01 (3.4675e-01)
Epoch: [0][1100/1118]	Time  2.524 ( 3.235)	Loss_CheXpert cls 6.5959e-01 (6.8340e-01)	Loss_CheXpert mse 3.4519e-01 (3.4652e-01)
3.4269381433138513e-06
Epoch: [0][  0/377]	Time 17.085 (17.085)	Loss_ChestXray14 cls 7.2001e-01 (7.2001e-01)	Loss_ChestXray14 mse 2.2638e-01 (2.2638e-01)
Epoch: [0][ 50/377]	Time  2.514 ( 2.868)	Loss_ChestXray14 cls 7.1421e-01 (7.1563e-01)	Loss_ChestXray14 mse 2.3082e-01 (2.2969e-01)
Epoch: [0][100/377]	Time  2.527 ( 2.722)	Loss_ChestXray14 cls 7.1129e-01 (7.1316e-01)	Loss_ChestXray14 mse 2.3363e-01 (2.3054e-01)
Epoch: [0][150/377]	Time  2.534 ( 2.672)	Loss_ChestXray14 cls 7.0209e-01 (7.1089e-01)	Loss_ChestXray14 mse 2.2734e-01 (2.3102e-01)
Epoch: [0][200/377]	Time  2.521 ( 2.644)	Loss_ChestXray14 cls 6.9946e-01 (7.0856e-01)	Loss_ChestXray14 mse 2.3267e-01 (2.3153e-01)
Epoch: [0][250/377]	Time  2.724 ( 2.628)	Loss_ChestXray14 cls 6.9563e-01 (7.0635e-01)	Loss_ChestXray14 mse 2.3361e-01 (2.3196e-01)
Epoch: [0][300/377]	Time  2.518 ( 2.615)	Loss_ChestXray14 cls 6.9429e-01 (7.0426e-01)	Loss_ChestXray14 mse 2.3046e-01 (2.3228e-01)
Epoch: [0][350/377]	Time  2.525 ( 2.610)	Loss_ChestXray14 cls 6.8820e-01 (7.0214e-01)	Loss_ChestXray14 mse 2.3452e-01 (2.3265e-01)
7.710588802556373e-06
Epoch: [0][  0/107]	Time 15.845 (15.845)	Loss_RSNAPneumonia cls 7.1879e-01 (7.1879e-01)	Loss_RSNAPneumonia mse 1.8809e-01 (1.8809e-01)
Epoch: [0][ 50/107]	Time  2.516 ( 2.851)	Loss_RSNAPneumonia cls 7.2698e-01 (7.1801e-01)	Loss_RSNAPneumonia mse 1.8807e-01 (1.8875e-01)
Epoch: [0][100/107]	Time  2.552 ( 2.710)	Loss_RSNAPneumonia cls 7.0800e-01 (7.1600e-01)	Loss_RSNAPneumonia mse 1.8991e-01 (1.8879e-01)
1.3707658621964214e-05
Epoch: [0][ 0/75]	Time 34.402 (34.402)	Loss_VinDrCXR cls 7.0433e-01 (7.0433e-01)	Loss_VinDrCXR mse 1.5986e-01 (1.5986e-01)
Epoch: [0][50/75]	Time  2.513 ( 3.386)	Loss_VinDrCXR cls 6.9701e-01 (7.0137e-01)	Loss_VinDrCXR mse 1.6461e-01 (1.6553e-01)
2.1418106498249934e-05
Epoch: [0][0/3]	Time 47.899 (47.899)	Loss_Shenzhen cls 6.8567e-01 (6.8567e-01)	Loss_Shenzhen mse 1.2766e-01 (1.2766e-01)
Val_MIMIC: [ 0/15]	Time 49.037 (49.037)	Loss 6.4064e-01 (6.4064e-01)
Val_CheXpert: [0/2]	Time 48.357 (48.357)	Loss 6.6388e-01 (6.6388e-01)
Val_ChestXray14: [ 0/57]	Time 12.564 (12.564)	Loss 6.8767e-01 (6.8767e-01)
Val_ChestXray14: [50/57]	Time  0.569 ( 0.938)	Loss 6.8751e-01 (6.8583e-01)
Val_RSNAPneumonia: [ 0/14]	Time 13.092 (13.092)	Loss 6.2627e-01 (6.2627e-01)
Val_VinDrCXR: [ 0/15]	Time 27.951 (27.951)	Loss 7.1817e-01 (7.1817e-01)
Val_Shenzhen: [0/1]	Time 18.180 (18.180)	Loss 7.0189e-01 (7.0189e-01)
Epoch 0000: avg_val_loss 0.67974, saving model to ./Models/swinv2_large_imagenet/Ark_MIMIC_CheXpert_ChestXray14_RSNAPneumonia_VinDrCXR_Shenzhen/Ark_MIMIC_CheXpert_ChestXray14_RSNAPneumonia_VinDrCXR_Shenzhen
>>MIMIC Disease = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']
>>MIMIC:Student AUC = [0.4489	0.5371	0.5153	0.5292	0.5727	0.5199	0.5558	0.5189	0.4838	0.5335
 0.4014	0.4948	0.4249	0.5912], 
Teacher AUC = [0.5159	0.5448	0.5358	0.4694	0.5686	0.5679	0.5756	0.4632	0.47  	0.5295
 0.407 	0.5273	0.5197	0.5461]

>>MIMIC: Student mAUC = 0.5091, Teacher mAUC = 0.5172
>>CheXpert Disease = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']
>>CheXpert:Student AUC = [0.6207	0.5615	0.6144	0.4894	0.4316], 
Teacher AUC = [0.4827	0.4662	0.564 	0.546 	0.5122]

>>CheXpert: Student mAUC = 0.5435, Teacher mAUC = 0.5142
>>ChestXray14 Disease = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']
